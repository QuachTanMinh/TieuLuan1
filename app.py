import cv2
import numpy as np
import streamlit as st
from PIL import Image

st.title("üì∏ Demo x·ª≠ l√Ω ·∫£nh")

# Upload ·∫£nh
uploaded_file = st.file_uploader("T·∫£i ·∫£nh l√™n", type=["jpg", "jpeg", "png"])
if uploaded_file is not None:
    image = Image.open(uploaded_file)
    img_array = np.array(image)

    st.image(img_array, caption="·∫¢nh g·ªëc", use_container_width=True)

    option = st.selectbox(
        "Ch·ªçn lo·∫°i x·ª≠ l√Ω ·∫£nh",
        [
            "üöó Ti·ªÅn x·ª≠ l√Ω nh·∫≠n d·∫°ng bi·ªÉn s·ªë xe",
            "üõ∞Ô∏è C·∫£i thi·ªán ·∫£nh v·ªá tinh GIS",
            "üåô N√¢ng cao ch·∫•t l∆∞·ª£ng ·∫£nh √°nh s√°ng k√©m"
        ]
    )

    # üöó 1. Ti·ªÅn x·ª≠ l√Ω nh·∫≠n d·∫°ng bi·ªÉn s·ªë xe
    if option == "üöó Ti·ªÅn x·ª≠ l√Ω nh·∫≠n d·∫°ng bi·ªÉn s·ªë xe":
        gray = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY)

        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        contrast = clahe.apply(gray)

        bilateral = cv2.bilateralFilter(contrast, d=9, sigmaColor=75, sigmaSpace=75)

        edges = cv2.Canny(bilateral, 100, 200)

        st.image(gray, caption="·∫¢nh Grayscale", use_container_width=True, channels="GRAY")
        st.image(contrast, caption="TƒÉng t∆∞∆°ng ph·∫£n (CLAHE)", use_container_width=True, channels="GRAY")
        st.image(bilateral, caption="L·ªçc nhi·ªÖu (Bilateral Filter)", use_container_width=True, channels="GRAY")
        st.image(edges, caption="L√†m n·ªïi b·∫≠t bi√™n c·∫°nh (Canny)", use_container_width=True, channels="GRAY")

    # üõ∞Ô∏è 2. C·∫£i thi·ªán ·∫£nh v·ªá tinh GIS
    elif option == "üõ∞Ô∏è C·∫£i thi·ªán ·∫£nh v·ªá tinh GIS":
        ycrcb = cv2.cvtColor(img_array, cv2.COLOR_RGB2YCrCb)
        y, cr, cb = cv2.split(ycrcb)
        y_eq = cv2.equalizeHist(y)
        img_eq = cv2.merge((y_eq, cr, cb))
        img_eq = cv2.cvtColor(img_eq, cv2.COLOR_YCrCb2RGB)

        gaussian = cv2.GaussianBlur(img_eq, (9, 9), 10.0)
        unsharp = cv2.addWeighted(img_eq, 1.5, gaussian, -0.5, 0)

        bilateral = cv2.bilateralFilter(unsharp, d=9, sigmaColor=75, sigmaSpace=75)

        st.image(img_eq, caption="C√¢n b·∫±ng histogram", use_container_width=True)
        st.image(unsharp, caption="TƒÉng ƒë·ªô s·∫Øc n√©t (Unsharp Masking)", use_container_width=True)
        st.image(bilateral, caption="L√†m m∆∞·ª£t nh∆∞ng gi·ªØ chi ti·∫øt (Bilateral Filter)", use_container_width=True)

    # üåô 3. N√¢ng cao ch·∫•t l∆∞·ª£ng ·∫£nh √°nh s√°ng k√©m
    elif option == "üåô N√¢ng cao ch·∫•t l∆∞·ª£ng ·∫£nh √°nh s√°ng k√©m":
        ycrcb = cv2.cvtColor(img_array, cv2.COLOR_RGB2YCrCb)
        y, cr, cb = cv2.split(ycrcb)

        y = cv2.convertScaleAbs(y, alpha=1.2, beta=30)

        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        y_clahe = clahe.apply(y)

        img_clahe = cv2.merge((y_clahe, cr, cb))
        img_clahe = cv2.cvtColor(img_clahe, cv2.COLOR_YCrCb2RGB)

        denoised = cv2.fastNlMeansDenoisingColored(img_clahe, None, 10, 10, 7, 21)

        st.image(img_clahe, caption="·∫¢nh sau CLAHE", use_container_width=True)
        st.image(denoised, caption="·∫¢nh sau gi·∫£m nhi·ªÖu (Denoising)", use_container_width=True)
